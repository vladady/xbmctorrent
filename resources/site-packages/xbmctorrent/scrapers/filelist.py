from xbmctorrent import plugin
from xbmctorrent.scrapers import scraper
from xbmctorrent.ga import tracked
from xbmctorrent.caching import cached_route
from xbmctorrent.utils import ensure_fanart


# Temporary, will be fixed later by them
IMMUNICITY_FILELIST_URL = "http://filelist.ro"
BASE_URL = "%s/" % (plugin.get_setting("immunicity", bool) and IMMUNICITY_FILELIST_URL or plugin.get_setting("base_filelist"))

HEADERS = {
    "Referer": BASE_URL,
}


CATEGORIES = [
    ("Filme XviD", 1),
    ("Filme DVD", 2),
    ("Filme DVD-RO", 3),
    ("Filme HD", 4),
    ("Filme VCD", 5),
    ("Filme Vechi", 6),
    ("Programe", 8),
    ("Jocuri PC", 9),
    ("Jocuri Console", 10),
    ("Audio", 11),
    ("Videoclip", 12),
    ("Sport", 13),
    ("TV", 14),
    ("Desene", 15),
    ("Docs", 16),
    ("Linux", 17),
    ("Diverse", 18),
    ("Filme HD-RO", 19),
    ("Blu-ray", 20),
    ("HDTV", 21),
    ("Mobile", 22),
    ("SDTV", 23),
    ("Anime", 24),
    ("Toate", 0)
]

if plugin.get_setting("porn", bool):
    CATEGORIES += [ ("XXX", 7)]
#######   start helpers ##########
STATIC_VARS = { "cookie" : False }

# Cache TTLs
DEFAULT_TTL = 24 * 3600 # 24 hours

def url_get(url, params={}, headers={}, post = None):
    from xbmctorrent.utils import url_get as url_get_origin

    if not STATIC_VARS["cookie"]:
        import os, xbmc, urllib2, cookielib

        sid_file = os.path.join(xbmc.translatePath('special://temp/'), 'plugin.video.xbmctorrent.filelist.cookies.dat') #
        cookiejar = cookielib.MozillaCookieJar(sid_file)

        if not os.path.isfile(sid_file):
            cookiejar.save()

        cookiejar.load()
        STATIC_VARS["cookie"] = cookiejar

        opener = urllib2.build_opener(urllib2.HTTPCookieProcessor(cookiejar))
        urllib2.install_opener(opener)

    result = url_get_origin(url, params, headers, post)
    STATIC_VARS["cookie"].save()

    return result

#helper from steeve for torrent playback
def from_torrent_url(url):
    import base64
    import bencode
    import hashlib
    import urllib
    torrent_data = url_get(url, headers = HEADERS)
    #torrent_data = url_get(url)
    metadata = bencode.bdecode(torrent_data)
    hashcontents = bencode.bencode(metadata['info'])
    digest = hashlib.sha1(hashcontents).digest()
    b32hash = base64.b32encode(digest)
    params = {
        'dn': metadata['info']['name'],
        'tr': metadata['announce'],
    }
    plugin.log.info(params)
    paramstr = urllib.urlencode(params)
    return 'magnet:?%s&%s' % ('xt=urn:btih:%s' % b32hash, paramstr)
#end of helper

#helper for playback
@plugin.route("/play_torrent/<uri>")
def play_torrent(uri):
    from xbmctorrent.player import TorrentPlayer
    uri = from_torrent_url(uri)
    # if plugin.get_setting("magnet_boost", bool):
    #     plugin.log.info("Enabled magnet booster")
    #     uri = _boost_magnet(uri)
    TorrentPlayer().init(uri).loop()


######################## end helpers #########################

@scraper("Filelist.ro Scraper")
@plugin.route("/filelist")
@ensure_fanart
#@tracked
def filelist_index():
    #yield {"label": "Search", "path": plugin.url_for("filelist_search")}
    def make_cats(root, prefix=""):
        for cat in root:
            yield {
                "label": "%s%s" % (prefix, cat[0]),
                "path": plugin.url_for("filelist_page", cat=cat[1], page=0),
            }
            if len(cat) > 2:
                for entry in make_cats(cat[2], prefix="%s    " % prefix):
                    yield entry

    for cat in make_cats(CATEGORIES):
        yield cat


@plugin.route("/filelist/<cat>/<page>")
#@cached_route(ttl=DEFAULT_TTL)
@ensure_fanart
#@tracked
def filelist_page(cat, page):
    import re
    from bs4 import BeautifulSoup
    from urlparse import urljoin
    
    page = int(page)
    url = urljoin(BASE_URL, "browse.php")

    html_data = url_get(url, params = {"cat": cat, "page": page}, headers = HEADERS)
    soup = BeautifulSoup(html_data, "html5lib")
    
    login = soup.find('input', {"value": "Login"})
    #print "login: %s" % login
    if login is not None:
      plugin.notify("You have to login", 'Msg', 100)
      _filelist_login(referer=BASE_URL)
      html_data = url_get(url, params = {"cat": cat, "page": page}, headers = HEADERS)
      soup = BeautifulSoup(html_data, "html5lib")
  
    trs = soup.find('table', {"class": "visitedlinks"}).findAll('tr')[1:]
 

    for tr in trs:
        tds = tr.findAll('td')
        title = tds[1].find('a').text
        link = tds[2].find('a')["href"]
        link = urljoin(BASE_URL, link)

        yield {
            "label": title,
            "path": plugin.url_for("play_torrent", uri=link),
            #"path": plugin.url_for("filelist_page", cat=cat, page=page+1),
            "is_playable": True,
        }
    next_page = {
        "label": "Next page...",
        "path": plugin.url_for("filelist_page", cat=1, page=0),
        "is_playable": False,
    }

    yield next_page


def _filelist_login(referer = BASE_URL):
    from bs4 import BeautifulSoup
    from urlparse import urljoin
    
    HEADERS["Referer"] = urljoin(BASE_URL, 'login.php')
    HEADERS["Origin"] = BASE_URL
    HEADERS["Content-Type"] = "application/x-www-form-urlencoded"

    values = {
        "username": plugin.get_setting("filelist_user"),
        "password": plugin.get_setting("filelist_pass"),
        "unlock": 1
    }

    html_data = url_get(urljoin(BASE_URL, "takelogin.php"), post=values, headers=HEADERS)
    #soup = BeautifulSoup(html_data, "html5lib")
    
    