from xbmctorrent import plugin
from xbmctorrent.scrapers import scraper
from xbmctorrent.ga import tracked
from xbmctorrent.caching import cached_route
from xbmctorrent.utils import ensure_fanart


# Temporary, will be fixed later by them
IMMUNICITY_IPLAY_URL = "http://localhost/drupal7/"
#BASE_URL = "%s/" % (plugin.get_setting("immunicity", bool) and IMMUNICITY_IPLAY_URL or plugin.get_setting("base_iplay"))
BASE_URL = "http://localhost/drupal7/"
HEADERS = {
    "Referer": BASE_URL,
}


CATEGORIES = [
    ("Movies", 29),
    ("Movies DVDR", 202),
    ("Music videos", 203),
    ("Movie clips", 204),
    ("TV shows", 205),
    ("Handheld", 206),
    ("HD - Movies", 207),
    ("HD - TV shows", 208),
    ("3D", 209),
    ("Other", 299),
]

if plugin.get_setting("porn", bool):
    CATEGORIES += [
        ("Porn", 500, [
            ("Movies", 501),
            ("Movies DVDR", 502),
            ("HD - Movies", 503),
            ("Movie clips", 504),
            ("Other", 599),
        ]),
    ]
STATIC_VARS = { "cookie" : False }

# Cache TTLs
DEFAULT_TTL = 24 * 3600 # 24 hours

def url_get(url, params={}, headers={}, post = None):
    from xbmctorrent.utils import url_get as url_get_origin

    if not STATIC_VARS["cookie"]:
        import os, xbmc, urllib2, cookielib

        sid_file = os.path.join(xbmc.translatePath('special://temp/'), 'plugin.video.xbmctorrent.iplay.cookies.dat') #
        cookiejar = cookielib.MozillaCookieJar(sid_file)

        if not os.path.isfile(sid_file):
            cookiejar.save()

        cookiejar.load()
        STATIC_VARS["cookie"] = cookiejar

        opener = urllib2.build_opener(urllib2.HTTPCookieProcessor(cookiejar))
        urllib2.install_opener(opener)

    result = url_get_origin(url, params, headers, post)
    #result = url_get_origin(url, params, headers)
    STATIC_VARS["cookie"].save()

    return result

@scraper("Iplay")
@plugin.route("/iplay")
@ensure_fanart
@tracked
def iplay_index():
    _iplay_login()
    #yield {"label": "Search", "path": plugin.url_for("iplay_search")}
    def make_cats(root, prefix=""):
        for cat in root:
            yield {
                "label": "%s%s" % (prefix, cat[0]),
                "path": plugin.url_for("iplay_page", cat=cat[1], page=0),
            }
            if len(cat) > 2:
                for entry in make_cats(cat[2], prefix="%s    " % prefix):
                    yield entry

    for cat in make_cats(CATEGORIES):
        yield cat


@plugin.route("/iplay/<cat>/<page>")
#@cached_route(ttl=DEFAULT_TTL)
@ensure_fanart
@tracked
def iplay_page(cat, page):
    import re
    from bs4 import BeautifulSoup
    from urlparse import urljoin
    from xbmctorrent.utils import url_get

    page = int(page)
    url = urljoin(BASE_URL, "test/proxy.php")
    html_data = url_get(url, params = {"cat": cat, "page": page}, headers = HEADERS)
    soup = BeautifulSoup(html_data, "html5lib")

    nodes = soup.findAll('a', 'torrent')

    next_page = {
        "label": "Next page...",
        "path": plugin.url_for("iplay_page", cat = cat, page = page + 1),
        "is_playable": False,
    }

    for node in nodes:
        text = "%s" % node.get('title')
        torrent_node = node.parent.find('img', {"class": "dld"}).parent

        yield {
            "label": text,
            "path": plugin.url_for("play", uri=torrent_node["href"]),
            "is_playable": False,
        }
    #print 'DBG URL:' + url
    yield next_page


def _iplay_login(referer = BASE_URL):
    from bs4 import BeautifulSoup
    from urlparse import urljoin
    from xbmctorrent.utils import url_get

    html_data = url_get(urljoin(BASE_URL, "user"))
    
    soup = BeautifulSoup(html_data, "html5lib")
    form_build_id = soup.find('input', {"name": "form_build_id"}).get("value")
    #plugin.notify(form_build_id)
    
    HEADERS["Referer"] = referer
    HEADERS["Origin"] = BASE_URL
    HEADERS["Content-Type"] = "application/x-www-form-urlencoded"

    values = {
        "name": "admin",
        "pass": "admin",
        "form_id": "user_login",
        "form_build_id": form_build_id,
        "op": "Log in",
        #"returnto": "/browse.php"
    }
    
    # #values = None

    html_data = url_get(urljoin(BASE_URL, "user"), post=values, headers = HEADERS)
    plugin.notify(html_data)
    # #html_data = url_get(urljoin(BASE_URL, "test/proxy.php"), headers=HEADERS)
    #soup = BeautifulSoup(html_data, "html5lib")
    
    # #login = soup.find('div', {"id": "ilogin"})
    #login = soup.find('form', {"id": "user-login"})
    
    # if login is not None:
    #     plugin.notify("You have to login", 'Msg', 100)
    # else:
    #     plugin.notify('Logged in', 'Msg', 100)
    return ""
    #return html_data

